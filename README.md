# ğŸ§  Transformer Federado para AnÃ¡lisis de TrÃ¡fico de Red
**Proyecto del curso de Inteligencia Artificial (C++)**  
**Integrantes:** Paolo JesÃºs Mostajo Alor Â· Alexander Carpio Mamani Â· Anthony BriceÃ±o Quiroz

---

## ğŸš© Problema
Los IDS (Intrusion Detection Systems) requieren grandes volÃºmenes de trÃ¡fico de red para entrenar modelos robustos. Centralizar esos datos:
- es **lento** y **costoso**,
- **vulnera la privacidad**,
- y dificulta escalar a mÃºltiples dominios/redes.

## ğŸ’¡ SoluciÃ³n
Entrenar un **Transformer Federado**: cada nodo/cliente aprende localmente sobre su propio trÃ¡fico y solo comparte **pesos del modelo** (no los datos crudos).  
Agregamos con **FedAvg** en un servidor central y repetimos por rondas.

**Ventajas**  
- **Privacidad:** los datos nunca salen de cada cliente.  
- **Eficiencia:** se envÃ­an solo parÃ¡metros, no millones de paquetes.  
- **Escalabilidad:** mÃ¡s nodos â‡’ mÃ¡s inteligencia global.

---

## ğŸ§± Arquitectura (visiÃ³n general)

       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                    Servidor (FedAvg)               â”‚
       â”‚ 1) EnvÃ­a modelo global  4) Promedia pesos (FedAvg) â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚                           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Cliente 1 â”‚ 2) Entrena localmente con su dataset â”‚ Cliente 2 â”‚
â”‚ (NSL-KDD split) â”‚ 3) Devuelve pesos actualizados â”‚ (NSL-KDD split) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜



---

## ğŸ“Š Dataset
- **NSL-KDD** (Kaggle, 2019).  
  Archivos tÃ­picos: `KDDTrain+.txt`, `KDDTest+.txt`.  
  *Uso:* convertir a numÃ©rico (one-hot/label encode), normalizar, y **particionar** en 2â€“3 subconjuntos (uno por cliente).

> Referencia: Kaggle â€“ â€œNSL-KDDâ€ (2019).

---

## ğŸ§© MetodologÃ­a
1. **Simular 2 o 3 clientes** federados (nodos) en **una sola mÃ¡quina**.  
2. **Preprocesar NSL-KDD** (encoding + normalizaciÃ³n + split por cliente).  
3. Entrenar un **Transformer Encoder pequeÃ±o** en cada cliente (C++ con kernels en CUDA).  
4. Implementar **servidor de agregaciÃ³n** con **FedAvg()**.  
5. **Comparar** contra un entrenamiento **centralizado** (mismo modelo, datos fusionados).  
6. Reportar **precisiÃ³n/F1** y **costos de comunicaciÃ³n** (tamaÃ±o de pesos por ronda).

---

## ğŸ—‚ï¸ Estructura sugerida del repositorio
â”œâ”€â”€ CMakeLists.txt
â”œâ”€â”€ include/
â”‚ â”œâ”€â”€ transformer.hpp
â”‚ â”œâ”€â”€ fedavg.hpp
â”‚ â””â”€â”€ dataloader.hpp
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ transformer.cu
â”‚ â”œâ”€â”€ client.cpp
â”‚ â”œâ”€â”€ server.cpp
â”‚ â””â”€â”€ centralized.cpp
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # KDDTrain+.txt, KDDTest+.txt
â”‚ â”œâ”€â”€ processed/ # *.csv / *.bin normalizados
â”‚ â””â”€â”€ splits/ # client1.csv, client2.csv, client3.csv
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ preprocess_nslkdd.py
â”‚ â”œâ”€â”€ split_clients.py
â”‚ â””â”€â”€ run_federated.sh
â”œâ”€â”€ configs/
â”‚ â”œâ”€â”€ model.yaml # d_model, n_heads, n_layers, ff_dim, dropoutâ€¦
â”‚ â”œâ”€â”€ train_fed.yaml # rounds, local_epochs, batch_size, lrâ€¦
â”‚ â””â”€â”€ train_central.yaml
â””â”€â”€ README.md




---

## âš™ï¸ Requisitos
- **CMake â‰¥ 3.24**
- **CUDA â‰¥ 12.x**, toolkit y driver compatibles
- **GCC/Clang** con soporte C++17
- **Python 3.9+** (solo para *scripts* de preprocesamiento)
- (Opcional) **vcpkg/conan** para gestionar dependencias C++ si se usan

---
