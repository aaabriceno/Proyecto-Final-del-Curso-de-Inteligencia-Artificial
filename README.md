#  Transformer Federado para An√°lisis de Tr√°fico de Red
**Proyecto del curso de Inteligencia Artificial (C++)**  
**Integrantes:** Paolo Jes√∫s Mostajo Alor ¬∑ Alexander Carpio Mamani ¬∑ Anthony Brice√±o Quiroz

---

##  Problema
Los sistemas de detecci√≥n de intrusos (IDS) necesitan grandes vol√∫menes de tr√°fico de red para entrenar modelos robustos. Centralizar esos datos:
- puede ser **costoso** y **lento**,
- **afecta la privacidad**,
- y no siempre es posible en escenarios distribuidos (distintas organizaciones o redes).

---

##  Enfoque propuesto
Implementamos un **modelo tipo Transformer** para la detecci√≥n de ataques en el dataset **NSL‚ÄëKDD**, y lo usamos en un esquema de **aprendizaje federado**:

- Cada cliente entrena localmente un peque√±o **MLP en CUDA** sobre la representaci√≥n generada por el Transformer.
- Solo se comparten los **pesos del MLP** (no los datos crudos).
- Un servidor central realiza un **promedio de pesos (FedAvg)** y eval√∫a el modelo global.

**Ventajas principales**
- **Privacidad:** los datos permanecen en cada cliente.
- **Menor comunicaci√≥n:** se env√≠an solo par√°metros, no todo el dataset.
- **Mejor generalizaci√≥n:** el modelo global ha visto patrones de varios clientes.

---

##  Dataset: NSL‚ÄëKDD
- Dataset cl√°sico para detecci√≥n de intrusiones.  
- En este proyecto se utilizan los archivos:
  - `NSL_KDD-master/KDDTrain+.txt`
  - `NSL_KDD-master/KDDTest+.txt`

Cada registro de conexi√≥n se transforma en **4 tokens**:
- Token 0: one‚Äëhot de `protocol_type`, `service` y `flag`.
- Tokens 1‚Äì3: subconjuntos de atributos num√©ricos normalizados (duraci√≥n, bytes, conteos, etc.).

Estos 4 tokens son la secuencia de entrada del Transformer.

---

## üß© Arquitectura del modelo

### 1. TokenEmbedding (`transformer.h`)
Convierte cada uno de los 4 tokens en un vector de dimensi√≥n `d_model = 64`:
- Para cada token se aplica una matriz de pesos distinta.
- La salida es una secuencia de tama√±o `4 √ó 64`.

### 2. Bloque Transformer (`transformer.h`)
Implementado desde cero en C++:
- **MultiHeadAttention** con varias cabezas de atenci√≥n.
- **FeedForward** totalmente conectada con activaci√≥n ReLU.
- **LayerNorm** y conexiones residuales.

Se obtiene una representaci√≥n por token; para clasificaci√≥n usamos el primer token (`H[0]`) como vector ‚ÄúCLS‚Äù.

### 3. Clasificador MLP en CUDA (`transformer.cu` / `average.cu`)
Un MLP peque√±o implementado con kernels CUDA:
- Capa densa 64 ‚Üí 128 con ReLU.
- Capa densa 128 ‚Üí `num_classes`.
- Softmax + cross‚Äëentropy para la p√©rdida.
- Optimizador **Adam** implementado tambi√©n en CUDA.

---

##  Entrenamiento centralizado (`transformer.cu`)

El archivo `transformer.cu` entrena el modelo de forma **centralizada**:
1. Carga `KDDTrain+.txt` y `KDDTest+.txt` desde `NSL_KDD-master/`.
2. Preprocesa el dataset y construye los 4 tokens por ejemplo (`NSLKDD`).
3. Pasa cada ejemplo por:
   - `TokenEmbedding` ‚Üí `Transformer` ‚Üí vector CLS (64).
   - MLP en CUDA (batch de tama√±o configurable).
4. Entrena el MLP con Adam durante varias √©pocas.
5. Eval√∫a en el conjunto de prueba y muestra la **accuracy**.
6. Guarda los pesos del MLP en `mlp_model.bin`:
   - `MLP_CUDA::save_weights("mlp_model.bin")`.

Este flujo sirve como baseline centralizado y como base para los clientes federados.

---

##  Aprendizaje federado con 3 clientes (`average.cu` + Colab)

La parte federada se centra en el **MLP final**:

1. **Clientes (por ejemplo, 3 Colabs)**
   - Cada Colab entrena un MLP con la misma arquitectura (`MLP_CUDA` o equivalente) sobre un subconjunto de datos.
   - Al finalizar, guarda sus pesos en un archivo binario, por ejemplo:
     - `mlp_model_1.bin`
     - `mlp_model_2.bin`
     - `mlp_model_3.bin`
   - Solo se env√≠an estos archivos al servidor (no los datos).

2. **Servidor de agregaci√≥n (`average.cu`)**
   - Carga el conjunto de prueba `KDDTest+.txt`.
   - Crea un modelo `MLP_CUDA mlp_avg(...)` y pone todos sus pesos en cero (`zero_weights()`).
   - Para cada archivo `mlp_model_i.bin`:
     - Crea un MLP temporal y carga los pesos.
     - Suma sus pesos al acumulador con `accumulate_mlp(mlp_avg, tmp)`.
   - Al final divide todos los pesos acumulados entre K (n√∫mero de clientes) con `divide_mlp(mlp_avg, K)`:
     - Esto implementa **Federated Averaging (FedAvg)**:
       \[
       W_{\text{global}} = \frac{1}{K} \sum_{k=1}^{K} W_k
       \]
   - Eval√∫a `mlp_avg` sobre el conjunto de prueba usando el mismo flujo:
     - `TokenEmbedding` ‚Üí `Transformer` ‚Üí CLS ‚Üí `mlp_avg.predict`.
   - Imprime la **accuracy final del modelo federado**.

En resumen: el servidor construye un modelo global a partir del promedio de los pesos entrenados en 3 clientes distintos.

---

##  Archivos principales del proyecto
- `transformer.h`  
  Implementaci√≥n del embedding de tokens, capas Transformer (atenci√≥n multi‚Äëcabeza, feedforward, layernorm) y el contenedor `Transformer`.

- `transformer.cu`  
  Entrenamiento centralizado de Transformer + MLP en CUDA sobre NSL‚ÄëKDD, y guardado de pesos en `mlp_model.bin`.

- `average.cu`  
  Carga el conjunto de prueba, recibe 3 modelos MLP entrenados (`mlp_model_1.bin`, `mlp_model_2.bin`, `mlp_model_3.bin`), realiza FedAvg y eval√∫a la accuracy final.

- `finalTransformer.ipynb`  
  Notebook de Colab para entrenar el modelo en la nube (por ejemplo, simulando cada cliente federado) y exportar los archivos `.bin` de pesos.

---

##  Requisitos
- **CUDA** con soporte para `nvcc` (probado en versiones recientes).
- **Compilador C++17** (por ejemplo, `g++`).
- Dataset **NSL‚ÄëKDD** ubicado en `NSL_KDD-master/` con los archivos:
  - `KDDTrain+.txt`
  - `KDDTest+.txt`
- (Opcional) Google Colab para entrenar los modelos de cada cliente y descargar los `.bin`.

---

## ‚ñ∂ C√≥mo compilar y ejecutar

Compilaci√≥n b√°sica (ejemplo):

```bash
nvcc transformer.cu -o transformer -std=c++17
nvcc average.cu     -o average    -std=c++17
```

1. **Entrenamiento centralizado**  
   ```bash
   ./transformer
   ```
   Esto entrena el modelo en `KDDTrain+.txt`, eval√∫a en `KDDTest+.txt` y genera `mlp_model.bin`.

2. **Escenario federado (3 clientes)**
   - Entrena el MLP en 3 entornos distintos (por ejemplo, 3 Colabs) y guarda:
     - `mlp_model_1.bin`, `mlp_model_2.bin`, `mlp_model_3.bin`.
   - Copia esos archivos al directorio del proyecto.
   - Ejecuta:
     ```bash
     ./average
     ```
   - El programa calcular√° el promedio de los pesos y mostrar√° la **accuracy final (ensemble federado)**.

---

